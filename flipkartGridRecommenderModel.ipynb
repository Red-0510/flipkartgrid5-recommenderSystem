{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PEnxealcfIjM",
        "outputId": "da745351-dcde-4d16-cfb1-931ea8d8fb6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "orbax-checkpoint 0.3.3 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n",
            "pydantic 2.1.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.4.0 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pymongo\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getDataFiles():\n",
        "  connection_string = <Add your database url>\n",
        "  client = MongoClient(connection_string)\n",
        "  db = client['flipkartDB']\n",
        "  collections = ['products','transactions','interactions',\"users\"]\n",
        "  for name in collections:\n",
        "    collection = db[name]\n",
        "    query={}\n",
        "    cursor = collection.find(query)\n",
        "    df = pd.DataFrame(list(cursor))\n",
        "    df.to_csv(f\"/content/{name}.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "getDataFiles()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ObJYxwxifPgZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "# from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7VJ0_WKW12s"
      },
      "source": [
        "###Data Loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SjqyzL2fT-8",
        "outputId": "10513ee3-ca8a-49f9-d502-3ec0e3bdb56b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-88-40ef383028d2>:2: DtypeWarning: Columns (13,14,21,22,48,52,53,54,55,56,57,58,59,85,89,90,91,92,93,94,95,96,159,163,164,165,166,167,168,169,170,177,178) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  users = pd.read_csv(\"/content/flipkartDB.users.csv\")\n"
          ]
        }
      ],
      "source": [
        "interactions = pd.read_csv(\"/content/flipkartDB.interactions.csv\",dtype={\"userId\":str})\n",
        "users = pd.read_csv(\"/content/flipkartDB.users.csv\")\n",
        "products = pd.read_csv(\"/content/flipkartDB.products.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4mxDWPZfVna"
      },
      "outputs": [],
      "source": [
        "interactions = interactions.head(10000)\n",
        "products = products.head(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpR0TwnBfXz1"
      },
      "outputs": [],
      "source": [
        "interactions = interactions[[\"userId\",\"productId\",\"point\"]]\n",
        "products.rename(columns={\"_id\":\"productId\"},inplace=True)\n",
        "users.rename(columns={\"_id\":\"userId\"},inplace=True)\n",
        "# movies = movies[[\"name\",\"productId\"]]\n",
        "products['name']=products['name'] + ' ' + products['company'] + ' '+ products[\"description\"]\n",
        "\n",
        "merge_df = interactions.merge(products, on=\"productId\", how=\"left\")\n",
        "merge_df = merge_df[[\"userId\",\"productId\",\"name\",\"point\"]]\n",
        "# merge_df.rename(columns={\"name\":\"name\", \"userId\":\"userId\"}, inplace=True)\n",
        "# product = pd.DataFrame(products[\"productId\"].unique(), columns=[\"productId\",\"name\"])\n",
        "products_tf = tf.data.Dataset.from_tensor_slices(dict(products))\n",
        "products_tf = tf.data.Dataset.prefetch(products_tf,buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fIYVXENjZcL"
      },
      "outputs": [],
      "source": [
        "interactions_tf = tf.data.Dataset.prefetch(tf.data.Dataset.from_tensor_slices(dict(merge_df)), buffer_size=tf.data.AUTOTUNE)\n",
        "# Converting ratings dataset to map dataset\n",
        "interactions_map = interactions_tf.map( lambda x: {\n",
        "\"userId\": x[\"userId\"],\n",
        "\"productId\": x[\"productId\"],\n",
        "\"name\":x[\"name\"],\n",
        "\"point\": x[\"point\"]})\n",
        "# Creating a map_dataset of movie data\n",
        "product_map = products_tf.map(lambda x:x[\"name\"])\n",
        "product_dataset = products_tf.map(lambda x:{\n",
        "    \"productId\":x[\"productId\"],\n",
        "    \"name\":x[\"name\"]\n",
        "})\n",
        "product_ids = products_tf.map(lambda x:x[\"productId\"])\n",
        "# Generating unique values:\n",
        "unique_user_ids = users[\"userId\"].unique()\n",
        "unique_products = products[\"productId\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OESzFkdVW6IW"
      },
      "source": [
        "###defining Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeZoCiJakfsN"
      },
      "outputs": [],
      "source": [
        "class UserModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.use_timestamp = use_timestamp\n",
        "        self.user_embeddings = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_user_ids, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_user_ids)+1, 32)\n",
        "            ])\n",
        "    def call(self, inputs):\n",
        "        return self.user_embeddings(inputs[\"userId\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_ECGvcdkm2D"
      },
      "outputs": [],
      "source": [
        "class ProductModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        max_tokens = 10_000\n",
        "        self.product_embedding = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(\n",
        "                vocabulary=unique_products, mask_token=None),\n",
        "            tf.keras.layers.Embedding(len(unique_products)+1, 32)\n",
        "            ])\n",
        "        self.text_vectorizer =  tf.keras.layers.TextVectorization(max_tokens=max_tokens)\n",
        "        self.product_names_context_embedding = tf.keras.Sequential([\n",
        "            self.text_vectorizer,\n",
        "            tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "            tf.keras.layers.GlobalAveragePooling1D()\n",
        "            ])\n",
        "        self.text_vectorizer.adapt(product_map)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.concat([\n",
        "            self.product_embedding(inputs[\"productId\"]),\n",
        "            self.product_names_context_embedding(inputs[\"name\"])],\n",
        "              axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v1DxCcjkwnN"
      },
      "outputs": [],
      "source": [
        "class ProductRecommendModel(tfrs.models.Model):\n",
        "    def __init__(self, rating_weight, retrieval_weight):\n",
        "        super().__init__()\n",
        "        embedding_dimension = 32\n",
        "        self.query_model = tf.keras.Sequential([\n",
        "            UserModel(),\n",
        "            tf.keras.layers.Dense(embedding_dimension)\n",
        "          ])\n",
        "        self.candidate_model = tf.keras.Sequential([\n",
        "            ProductModel(),\n",
        "            tf.keras.layers.Dense(embedding_dimension)\n",
        "          ])\n",
        "        self.rating_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(1)\n",
        "          ])\n",
        "        self.retrieval_task = tfrs.tasks.Retrieval(\n",
        "            metrics=tfrs.metrics.FactorizedTopK(\n",
        "                candidates=product_dataset.batch(128).map(self.candidate_model)))\n",
        "        self.rating_task = tfrs.tasks.Ranking(\n",
        "            loss=tf.keras.losses.MeanSquaredError(),\n",
        "            metrics=[tf.keras.metrics.RootMeanSquaredError()\n",
        "          ])\n",
        "       # The loss weights.\n",
        "        self.rating_weight = rating_weight\n",
        "        self.retrieval_weight = retrieval_weight\n",
        "    def call(self, features) -> tf.Tensor:\n",
        "        user_embeddings = self.query_model({\"userId\": features[\"userId\"]})\n",
        "        product_embeddings = self.candidate_model({\"productId\":features[\"productId\"],\"name\":features[\"name\"]})\n",
        "        return (user_embeddings, product_embeddings, self.rating_model(tf.concat([user_embeddings, product_embeddings],axis=1)))\n",
        "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
        "\n",
        "        ratings = features.pop(\"point\")\n",
        "        user_embeddings, product_embeddings, rating_predictions = self(features)\n",
        "        # We compute the loss for each task.\n",
        "        rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)\n",
        "        retrieval_loss = self.retrieval_task(user_embeddings, product_embeddings)\n",
        "        # And combine them using the loss weights.\n",
        "        return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5B0ZdIrlBLZ"
      },
      "outputs": [],
      "source": [
        "model = ProductRecommendModel(2, 1)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.5),metrics=['accuracy'])\n",
        "# model.fit(train, epochs=10)\n",
        "# <_MapDataset element_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None)>\n",
        "# here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crDhKiRRQJdJ"
      },
      "outputs": [],
      "source": [
        "train = interactions_map.take(8000)\n",
        "test = interactions_map.skip(8000).take(2000)\n",
        "cached_train = train.batch(128)\n",
        "cached_test = test.batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5D-pmKCk-T-",
        "outputId": "f216fbd7-1f79-4e7b-a02e-f05bf9c25b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 40s 612ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0209 - factorized_top_k/top_5_categorical_accuracy: 0.0233 - factorized_top_k/top_10_categorical_accuracy: 0.0249 - factorized_top_k/top_50_categorical_accuracy: 0.0342 - factorized_top_k/top_100_categorical_accuracy: 0.0415 - root_mean_squared_error: 592.3730 - loss: 692227.7042 - regularization_loss: 0.0000e+00 - total_loss: 692227.7042\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b476fc08100>"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(cached_train,epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFud8_zLQxBQ",
        "outputId": "0bbd7d4a-471d-4172-d804-5de041f24e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 11s 687ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0010 - factorized_top_k/top_50_categorical_accuracy: 0.0045 - factorized_top_k/top_100_categorical_accuracy: 0.0090 - root_mean_squared_error: 237.2788 - loss: 115072.0450 - regularization_loss: 0.0000e+00 - total_loss: 115072.0450\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.0005000000237487257,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.0010000000474974513,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.0044999998062849045,\n",
              " 'factorized_top_k/top_100_categorical_accuracy': 0.008999999612569809,\n",
              " 'root_mean_squared_error': 237.27883911132812,\n",
              " 'loss': 126557.9296875,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 126557.9296875}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(cached_test,return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CB7oZZwmMre",
        "outputId": "e7d96475-d18e-472f-fb76-e5dc1fd699df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7b476fb442e0>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scann = tfrs.layers.factorized_top_k.ScaNN(\n",
        "        model.query_model,\n",
        "        num_leaves=1000,\n",
        "        num_leaves_to_search=100,\n",
        "        num_reordering_candidates=100,\n",
        "        k=15)\n",
        "candidate_embeddings = product_dataset.batch(128).map(lambda x:model.candidate_model(x))\n",
        "# for i in lets_products_embeddings.take(5):\n",
        "#   print(i)\n",
        "scann.index_from_dataset(tf.data.Dataset.zip((product_ids.batch(128),candidate_embeddings)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgIC5MvwC6OE"
      },
      "outputs": [],
      "source": [
        "def decode_titles(titles):\n",
        "  def decode_bytes(data):\n",
        "    return data.decode('utf-8')\n",
        "# res = np.vectorize(decode)(titles.numpy())\n",
        "  data=[]\n",
        "  for i in titles:\n",
        "    data = np.vectorize(decode_bytes)(i.numpy())\n",
        "  return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-ly-Nd5CzuS"
      },
      "outputs": [],
      "source": [
        "def getRecommendations(userId):\n",
        "  _,titles = scann({\"userId\":tf.constant([userId])})\n",
        "  prods = decode_titles(titles)\n",
        "  res = {\"productId\":[],\"point\":[]}\n",
        "  test_data={\"userId\":tf.constant([userId])}\n",
        "  for data in prods:\n",
        "    res[\"productId\"].append(data)\n",
        "    row=products.loc[products[\"productId\"]==data]\n",
        "    row=row[\"name\"]\n",
        "    test_data[\"productId\"]=np.array([data])\n",
        "    test_data[\"name\"]=np.array([row])\n",
        "    _, _, rating = model(test_data)\n",
        "    res[\"point\"].append(int(rating[0][0]))\n",
        "  # for data in prods:\n",
        "  #   test_data[\"productId\"]=np.array([data])\n",
        "  df_res = pd.DataFrame(res)\n",
        "  # df_res=df_res.sort_values('point', ascending=False)\n",
        "  # recommends = np.array(df_res[\"productId\"])\n",
        "  # print(df_res)\n",
        "  return df_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NwAtleUKejQ"
      },
      "outputs": [],
      "source": [
        "def getUserRecommendations(userId):\n",
        "  user_res_df=getRecommendations(userId)\n",
        "  user_res_df=user_res_df.sort_values('point', ascending=False)\n",
        "  recommends = np.array(user_res_df[\"productId\"])\n",
        "  return list(recommends)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20eex5icvGb6"
      },
      "outputs": [],
      "source": [
        "def getLocationRecommendations(location):\n",
        "  users_local = users.loc[users[\"location\"]==location].head(10)[\"userId\"]\n",
        "  recommends = pd.DataFrame()\n",
        "  for user in users_local:\n",
        "    local = getRecommendations(user)\n",
        "    recommends = recommends.append(local)\n",
        "  recommends = recommends.sort_values('point',ascending=False)\n",
        "  recommends = list(recommends['productId'])\n",
        "  return recommends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUmIClekM6UP"
      },
      "outputs": [],
      "source": [
        "def getAgeRecommendations(age):\n",
        "  users_local = users.loc[users[\"age\"]==age].head(10)[\"userId\"]\n",
        "  recommends = pd.DataFrame()\n",
        "  for user in users_local:\n",
        "    local = getRecommendations(user)\n",
        "    recommends = recommends.append(local)\n",
        "  recommends = recommends.sort_values('point',ascending=False)\n",
        "  recommends = list(recommends['productId'])\n",
        "  return recommends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP67t3_TEhNH"
      },
      "outputs": [],
      "source": [
        "getLocationRecommendations(\"Gujarat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCMWZmB8Mw2A"
      },
      "outputs": [],
      "source": [
        "getUserRecommendations(\"64df99c726ae34e9b5e8f4fe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRz2De3I7285"
      },
      "outputs": [],
      "source": [
        "getAgeRecommendations(\"Child\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7a-o7k-gVSG"
      },
      "outputs": [],
      "source": [
        "!pip install -q colabcode\n",
        "!pip install -q fastapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V9dvyaqgYYZ"
      },
      "outputs": [],
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI\n",
        "cc = ColabCode(port=12000, code=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d7qGTcrgkft"
      },
      "outputs": [],
      "source": [
        "app = FastAPI(title=\"ML Models as API on Google Colab\", description=\"with FastAPI and ColabCode\", version=\"1.0\")\n",
        "\n",
        "# @app.on_event(\"startup\")\n",
        "# def load_model():\n",
        "#     global model\n",
        "#     model = pickle.load(open(\"model_gb.pkl\", \"rb\"))\n",
        "\n",
        "@app.post(\"/api/home\")\n",
        "def get_predictions(data:dict):\n",
        "    try:\n",
        "        recommends = getUserRecommendations(data[\"userId\"])\n",
        "        print(type(recommends))\n",
        "        return recommends\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return {\"error\": e}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK3xN-5agmDw",
        "outputId": "26aadad8-58bb-4cd0-b3f0-ecacebf9ab76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-08-19T13:27:58+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://b18d-34-29-10-228.ngrok.io\" -> \"http://localhost:12000\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [924]\n",
            "INFO:uvicorn.error:Started server process [924]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:uvicorn.error:Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:uvicorn.error:Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n",
            "INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.210.100:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.210.100:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.210.100:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.210.100:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.210.100:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n",
            "<class 'list'>\n",
            "INFO:     117.239.204.225:0 - \"POST /api/home HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:uvicorn.error:Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:uvicorn.error:Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:uvicorn.error:Application shutdown complete.\n",
            "INFO:     Finished server process [924]\n",
            "INFO:uvicorn.error:Finished server process [924]\n"
          ]
        }
      ],
      "source": [
        "cc.run_app(app=app)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
